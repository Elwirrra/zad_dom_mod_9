# === IMPORTY ===


import os, io, json, functools
import pandas as pd
import streamlit as st
import joblib, boto3
from pydantic import BaseModel, ValidationError, conint, confloat
from pathlib import Path
from dotenv import load_dotenv
from langfuse import Langfuse
#from langfuse.decorators import observe
from langfuse.openai import OpenAI as LangfuseOpenAI


# === KONFIG ===


load_dotenv(Path(__file__).parent / ".env", override=True) 

client = LangfuseOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

BUCKET = os.getenv("SPACES_BUCKET")                 
ENDPOINT = os.getenv("AWS_ENDPOINT_URL_S3")             
ACCESS = os.getenv("AWS_ACCESS_KEY_ID")
SECRET = os.getenv("AWS_SECRET_ACCESS_KEY")
MODEL_KEY = os.getenv("MODEL_KEY")                   

REQUIRED = ["plec", "wiek", "czas_5km"]           

ERROR_MSG_MISSING = (
    "Brak wystarczajƒÖcych danych. Upewnij siƒô, ≈ºe wprowadzi≈Çe≈õ "
    "wiek, p≈Çeƒá i czas na 5km biegu!"
)

st.set_page_config(
    page_title="Predykcja czasu p√≥≈Çmaratonu",
    page_icon="üèÉ‚Äç‚ôÄÔ∏è",
    layout="wide"
)


# === STYL NAG≈Å√ìWKA ===


st.markdown("""
<style>
h1.app-title{
  font-size: 2.8rem; font-weight: 800; line-height: 1.1;
  letter-spacing:.2px; margin: .2rem 0 .4rem 0;
  background: linear-gradient(90deg,#0ea5e9 0%, #22c55e 100%);
  -webkit-background-clip: text; -webkit-text-fill-color: transparent;
}
p.app-subtitle{
  font-size: 2.18rem;    /* by≈Ço ~0.95rem */
  font-weight: 600;
  color: #475569;
  margin: .25rem 0 .9rem 0;
}
h1.app-title, p.app-subtitle{
  text-align: center !important;
  margin-left: auto; 
  margin-right: auto;
}
</style>
""", unsafe_allow_html=True)


st.markdown('<h1 class="app-title">üèÉ‚Äç‚ôÄÔ∏è Sprawd≈∫ jak szybki bƒôdziesz w p√≥≈Çmaratonie?</h1>', unsafe_allow_html=True)
st.markdown('<p class="app-subtitle">Podaj wiek, p≈Çeƒá i Tw√≥j czas na 5 km - resztƒô zrobiƒô za Ciebie.</p>', unsafe_allow_html=True)


# === FUNKCJE POMOCNICZE ===


def lf_start_trace(lf, **kwargs):
    """Zacznij trace niezale≈ºnie od wersji SDK."""
    if not lf:
        return None
    for name in ("create_trace", "trace", "start_trace"):
        fn = getattr(lf, name, None)
        if callable(fn):
            return fn(**kwargs)
    return None

def lf_start_span(parent, **kwargs):
    """Zacznij span niezale≈ºnie od wersji SDK."""
    if not parent:
        return None
    for name in ("create_span", "span", "start_span"):
        fn = getattr(parent, name, None)
        if callable(fn):
            return fn(**kwargs)
    return None

def lf_end_span(span, **kwargs):
    """Zako≈Ñcz span niezale≈ºnie od wersji SDK."""
    if not span:
        return
    # najczƒô≈õciej .end(output=...), ale czasem .update(output=...) lub .finish()
    for name in ("end", "update", "finish", "close"):
        fn = getattr(span, name, None)
        if callable(fn):
            try:
                fn(**kwargs)
            except TypeError:
                # spr√≥buj z samym output=...
                out = kwargs.get("output")
                if out is not None:
                    try:
                        fn(output=out)
                    except Exception:
                        pass
            break


@st.cache_resource
def _lf():
    if Langfuse is None:
        return None
    try:
        return Langfuse(
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
        )
    except Exception:
         return None

def observe(name: str):
    def deco(fn):
        @functools.wraps(fn)
        def wrapper(*args, **kwargs):
            lf = _lf()
            trace = lf_start_trace(lf, name=name)
            span  = lf_start_span(trace, name=name, input={"args": args, "kwargs": kwargs})
            try:
                result = fn(*args, **kwargs)
                lf_end_span(span, output=result)
                return result
            except Exception as e:
                lf_end_span(span, output={"error": str(e)})
                raise
        return wrapper
    return deco

@st.cache_resource
def get_langfuse():
    try:
        return Langfuse(
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
        )
    except:
        return None

def s3():
    return boto3.client(
        "s3",
        endpoint_url=ENDPOINT,
        aws_access_key_id=ACCESS,
        aws_secret_access_key=SECRET,
    )

@st.cache_resource(show_spinner=False)
def load_model():
    s3c = s3()
    # szybki pre-check: czy plik istnieje?
    try:
        s3c.head_object(Bucket=BUCKET, Key=MODEL_KEY)
    except Exception as e:
        raise FileNotFoundError(
            f"[diag] Nie ma pliku modelu pod kluczem '{MODEL_KEY}' w buckecie '{BUCKET}'. "
            f"Sprawd≈∫ nazwƒô/katalog w Spaces. B≈ÇƒÖd: {e}"
        )

    obj = s3c.get_object(Bucket=BUCKET, Key=MODEL_KEY)
    model = joblib.load(io.BytesIO(obj["Body"].read()))
    return model, MODEL_KEY

    
class Inputs(BaseModel):
    plec: str                # "K" lub "M"
    wiek: conint(ge=10, le=100)
    czas_5km: confloat(gt=10*60, lt=60*60)  # sekundy (10‚Äì60 min)


@observe(name="extract_with_llm")
def extract_with_llm(text: str) -> dict:

    # Twarde ograniczenia pomagajƒÖ modelowi i odsiejƒÖ bzdury
    schema = {
        "name": "inputs",
        "schema": {
            "type": "object",
            "properties": {
                "plec": {"type": "string", "enum": ["K","M", None]},
                "wiek": {"type": "integer", "minimum": 10, "maximum": 100},
                # czas w SEKUNDACH (10‚Äì60 minut ‚Üí 600‚Äì3600 s)
                "czas_5km": {"type": "number", "minimum": 600, "maximum": 3600}
            },
            "required": ["plec","wiek","czas_5km"],
            "additionalProperties": False
        }
    }

    # sys = (
    #     "Wyodrƒôbnij 'plec' (K/M), 'wiek' (w latach) oraz 'czas_5km' w **SEKUNDACH**.\n"
    #     "U≈ºytkownik mo≈ºe podawaƒá czas w minutach (np. '33 min'), w formacie 'MM:SS' albo 'HH:MM:SS'.\n"
    #     "Zawsze przelicz na sekundy i zwr√≥ƒá WY≈ÅƒÑCZNIE JSON zgodny ze schematem.\n"
    #     "Je≈õli kt√≥rejkolwiek informacji NIE podano wprost, zwr√≥ƒá warto≈õƒá null (NIE zgaduj).\n"
    #     "Przyk≈Çady:\n"
    #     " - 'kobieta, 34 lata, 5 km 27:30' ‚Üí {\"plec\":\"K\",\"wiek\":34,\"czas_5km\":1650}\n"
    #     " - 'M 40 lat, 5 km w 33 min'     ‚Üí {\"plec\":\"M\",\"wiek\":40,\"czas_5km\":1980}\n"
    #     " - 'K 19, 5km w 18m45s'          ‚Üí {\"plec\":\"K\",\"wiek\":19,\"czas_5km\":1125}\n"
    #     " - 'Mam 40 lat, 5 km w 25:10' ‚Üí {"plec": null, "wiek": 40, "czas_5km": 1510}\n"
    # )
        
    sys = """
    Wyodrƒôbnij 'plec' (K/M), 'wiek' (w latach) oraz 'czas_5km' w **SEKUNDACH**.
    U≈ºytkownik mo≈ºe podawaƒá czas w minutach (np. '33 min'), w formacie 'MM:SS' albo 'HH:MM:SS'.
    Zawsze przelicz na sekundy i zwr√≥ƒá WY≈ÅƒÑCZNIE JSON zgodny ze schematem.
    Je≈õli kt√≥rejkolwiek informacji NIE podano wprost, zwr√≥ƒá warto≈õƒá null (NIE zgaduj).

    Przyk≈Çady:
    - 'kobieta, 34 lata, 5 km 27:30'   ‚Üí {"plec":"K","wiek":34,"czas_5km":1650}
    - 'M 40 lat, 5 km w 33 min'        ‚Üí {"plec":"M","wiek":40,"czas_5km":1980}
    - 'K 19, 5km w 18m45s'             ‚Üí {"plec":"K","wiek":19,"czas_5km":1125}
    - 'Mam 40 lat, 5 km w 25:10'       ‚Üí {"plec": null, "wiek":40,"czas_5km":1510}
    """

    resp = client.chat.completions.create(
        model=os.getenv("OPENAI_MODEL","gpt-4o-mini"),
        temperature=0,
        messages=[
            {"role":"system","content": sys},
            {"role":"user","content": text}
        ],
        response_format={"type":"json_schema","json_schema": schema}
    )
    return json.loads(resp.choices[0].message.content)


def to_features(p: Inputs) -> pd.DataFrame:
    pace_min_per_km = (p.czas_5km / 60.0) / 5.0   # sek‚Üímin, /5 km = min/km
    return pd.DataFrame([{
        "wiek": p.wiek,
        "plec": p.plec,
        "start_druzynowy": "nie",
        "5km_tempo": pace_min_per_km,
    }])

def fmt_time(sec: float) -> str:
    h = int(sec // 3600)
    m = int((sec % 3600) // 60)
    s = int(sec % 60)
    if h > 0:
        return f"{h}:{m:02d}:{s:02d}"
    else:
        return f"{m}:{s:02d}"
         

# === UI ===


text = st.text_area(
    label="", 
    label_visibility="collapsed",
    placeholder="Np.: ‚ÄûMam 34 lata, kobieta, 5 km w 27:30‚Äù.",
    height=120,
    key="user_text",
)




if st.button("Policz", key="policz_main"):
    lf = get_langfuse()
    trace = lf_start_trace(lf, name="predykcja", input={"raw_text": text})


    try:
        # --- Twoje przetwarzanie ---
        data_raw = extract_with_llm(text)
        for k in REQUIRED:
            if not data_raw.get(k):
                raise ValueError(f"missing:{k}")
        data = Inputs(**data_raw)

        model, model_key = load_model()
        X = to_features(data)
        y_sec = float(model.predict(X)[0])

        # --- wynik dla u≈ºytkownika ---
        st.success(f"Szacowany wynik: {y_sec/60:.1f} min ({fmt_time(y_sec)})")
        st.caption(f"Model: {model_key}")

        # --- zapis do Langfuse ---
        if trace:
            trace.update(output={"pred": y_sec, "model_key": model_key})
            lf.flush()

    except Exception as e:
        st.error("Nie uda≈Ço siƒô policzyƒá wyniku, sprawd≈∫ czy wszystkie potrzebne dane zosta≈Çy wprowadzone.")
        if trace:
            trace.update(tags=["error"], output={"error": str(e)})
            lf.flush()



# === IMPORTY ===


import os, io, json, functools
import pandas as pd
import streamlit as st
import joblib, boto3
from pydantic import BaseModel, ValidationError, conint, confloat
from pathlib import Path
from dotenv import load_dotenv
from langfuse import Langfuse
from langfuse.openai import OpenAI as LangfuseOpenAI
import re


# === KONFIG ===


load_dotenv(Path(__file__).parent / ".env", override=True) 

client = LangfuseOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

BUCKET = os.getenv("SPACES_BUCKET")                 
ENDPOINT = os.getenv("AWS_ENDPOINT_URL_S3")             
ACCESS = os.getenv("AWS_ACCESS_KEY_ID")
SECRET = os.getenv("AWS_SECRET_ACCESS_KEY")
MODEL_KEY = os.getenv("MODEL_KEY")                   

REQUIRED = ["plec", "wiek", "czas_5km"]           

ERROR_MSG_MISSING = (
    "Brak wystarczajÄ…cych danych. Upewnij siÄ™, Å¼e wprowadziÅ‚eÅ› "
    "wiek, pÅ‚eÄ‡ i czas na 5km biegu!"
)

st.set_page_config(
    page_title="Predykcja czasu pÃ³Å‚maratonu",
    page_icon="ğŸƒâ€â™€ï¸",
    layout="wide"
)


# === STYL NAGÅÃ“WKA ===


st.markdown("""
<style>
h1.app-title{
  font-size: 2.8rem; font-weight: 800; line-height: 1.1;
  letter-spacing:.2px; margin: .2rem 0 .4rem 0;
  background: linear-gradient(90deg,#0ea5e9 0%, #22c55e 100%);
  -webkit-background-clip: text; -webkit-text-fill-color: transparent;
}
p.app-subtitle{
  font-size: 2.18rem;    /* byÅ‚o ~0.95rem */
  font-weight: 600;
  color: #475569;
  margin: .25rem 0 .9rem 0;
}
h1.app-title, p.app-subtitle{
  text-align: center !important;
  margin-left: auto; 
  margin-right: auto;
}
</style>
""", unsafe_allow_html=True)


st.markdown('<h1 class="app-title">ğŸƒâ€â™€ï¸ SprawdÅº jak szybki bÄ™dziesz w pÃ³Å‚maratonie?</h1>', unsafe_allow_html=True)
st.markdown('<p class="app-subtitle">Podaj wiek, pÅ‚eÄ‡ i TwÃ³j czas na 5 km - resztÄ™ zrobiÄ™ za Ciebie.</p>', unsafe_allow_html=True)


# === FUNKCJE POMOCNICZE ===


def lf_start_trace(lf, **kwargs):
    """Zacznij trace niezaleÅ¼nie od wersji SDK."""
    if not lf:
        return None
    for name in ("create_trace", "trace", "start_trace"):
        fn = getattr(lf, name, None)
        if callable(fn):
            return fn(**kwargs)
    return None

def lf_start_span(parent, **kwargs):
    """Zacznij span niezaleÅ¼nie od wersji SDK."""
    if not parent:
        return None
    for name in ("create_span", "span", "start_span"):
        fn = getattr(parent, name, None)
        if callable(fn):
            return fn(**kwargs)
    return None

def lf_end_span(span, **kwargs):
    """ZakoÅ„cz span niezaleÅ¼nie od wersji SDK."""
    if not span:
        return
    # najczÄ™Å›ciej .end(output=...), ale czasem .update(output=...) lub .finish()
    for name in ("end", "update", "finish", "close"):
        fn = getattr(span, name, None)
        if callable(fn):
            try:
                fn(**kwargs)
            except TypeError:
                # sprÃ³buj z samym output=...
                out = kwargs.get("output")
                if out is not None:
                    try:
                        fn(output=out)
                    except Exception:
                        pass
            break


@st.cache_resource
def _lf():
    if Langfuse is None:
        return None
    try:
        return Langfuse(
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
        )
    except Exception:
         return None

def observe(name: str):
    def deco(fn):
        @functools.wraps(fn)
        def wrapper(*args, **kwargs):
            lf = _lf()
            trace = lf_start_trace(lf, name=name)
            span  = lf_start_span(trace, name=name, input={"args": args, "kwargs": kwargs})
            try:
                result = fn(*args, **kwargs)
                lf_end_span(span, output=result)
                return result
            except Exception as e:
                lf_end_span(span, output={"error": str(e)})
                raise
        return wrapper
    return deco

@st.cache_resource
def get_langfuse():
    try:
        return Langfuse(
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
        )
    except:
        return None

def s3():
    return boto3.client(
        "s3",
        endpoint_url=ENDPOINT,
        aws_access_key_id=ACCESS,
        aws_secret_access_key=SECRET,
    )

@st.cache_resource(show_spinner=False)
def load_model():
    s3c = s3()
    # szybki pre-check: czy plik istnieje?
    try:
        s3c.head_object(Bucket=BUCKET, Key=MODEL_KEY)
    except Exception as e:
        raise FileNotFoundError(
            f"[diag] Nie ma pliku modelu pod kluczem '{MODEL_KEY}' w buckecie '{BUCKET}'. "
            f"SprawdÅº nazwÄ™/katalog w Spaces. BÅ‚Ä…d: {e}"
        )

    obj = s3c.get_object(Bucket=BUCKET, Key=MODEL_KEY)
    model = joblib.load(io.BytesIO(obj["Body"].read()))
    return model, MODEL_KEY

    
class Inputs(BaseModel):
    plec: str                # "K" lub "M"
    wiek: conint(ge=10, le=100)
    czas_5km: confloat(gt=10*60, lt=60*60)  # sekundy (10â€“60 min)


@observe(name="extract_with_llm")
def extract_with_llm(text: str) -> dict:

    # Twarde ograniczenia pomagajÄ… modelowi i odsiejÄ… bzdury
    schema = {
        "name": "inputs",
        "schema": {
            "type": "object",
            "properties": {
                "plec": {"type": "string", "enum": ["K","M", None]},
                "wiek": {"type": "integer", "minimum": 10, "maximum": 100},
                # czas w SEKUNDACH (10â€“60 minut â†’ 600â€“3600 s)
                "czas_5km": {"type": "number", "minimum": 600, "maximum": 3600}
            },
            "required": ["plec","wiek","czas_5km"],
            "additionalProperties": False
        }
    }

    sys = """
    WyodrÄ™bnij 'plec' (K/M), 'wiek' (w latach) oraz 'czas_5km' w SEKUNDACH.
    UÅ¼ytkownik moÅ¼e podaÄ‡ czas w minutach (np. '33 min'), w formacie 'MM:SS' albo 'HH:MM:SS'.
    Zawsze przelicz na sekundy i zwrÃ³Ä‡ WYÅÄ„CZNIE JSON zgodny ze schematem.
    JeÅ›li ktÃ³rejkolwiek informacji NIE podano wprost, zwrÃ³Ä‡ wartoÅ›Ä‡ null (NIE zgaduj).

    MAPOWANIE PÅCI:
    - JeÅ›li pada 'mÄ™Å¼czyzna', 'facet', 'chÅ‚opak', 'pan' â†’ zwrÃ³Ä‡ "M".
    - JeÅ›li pada 'kobieta', 'dziewczyna', 'pani' â†’ zwrÃ³Ä‡ "K".
    - JeÅ›li uÅ¼ytkownik poda imiÄ™ mÄ™skie (np. 'Jestem Piotrek/Piotr/PaweÅ‚/Marcin/Adam') â†’ "M".
    - JeÅ›li uÅ¼ytkownik poda imiÄ™ Å¼eÅ„skie (np. 'Jestem Ania/Anna/Kasia/Joanna/Magda') â†’ "K".
    - W razie niejednoznacznoÅ›ci â†’ null.

    PrzykÅ‚ady:
    - 'kobieta, 34 lata, 5 km 27:30'            â†’ {"plec":"K","wiek":34,"czas_5km":1650}
    - 'M 40 lat, 5 km w 33 min'                  â†’ {"plec":"M","wiek":40,"czas_5km":1980}
    - 'Jestem Piotrek, 47 lat, 5 km 40 min'      â†’ {"plec":"M","wiek":47,"czas_5km":2400}
    - 'Jestem Ania, 19 lat, 5km w 18m45s'        â†’ {"plec":"K","wiek":19,"czas_5km":1125}
    - 'Mam 40 lat, 5 km w 25:10'                 â†’ {"plec": null, "wiek":40,"czas_5km":1510}
    """
        
    

    resp = client.chat.completions.create(
        model=os.getenv("OPENAI_MODEL","gpt-4o-mini"),
        temperature=0,
        messages=[
            {"role":"system","content": sys},
            {"role":"user","content": text}
        ],
        response_format={"type":"json_schema","json_schema": schema}
    )
    return json.loads(resp.choices[0].message.content)


def to_features(p: Inputs) -> pd.DataFrame:
    pace_min_per_km = (p.czas_5km / 60.0) / 5.0   # sekâ†’min, /5 km = min/km
    return pd.DataFrame([{
        "wiek": p.wiek,
        "plec": p.plec,
        "start_druzynowy": "nie",
        "5km_tempo": pace_min_per_km,
    }])

def fmt_time(sec: float) -> str:
    h = int(sec // 3600)
    m = int((sec % 3600) // 60)
    s = int(sec % 60)
    if h > 0:
        return f"{h}:{m:02d}:{s:02d}"
    else:
        return f"{m}:{s:02d}"

def infer_gender_from_text(text: str) -> str | None:
    t = text.lower()
    male_kw = ["mÄ™Å¼czyzna","mezczyzna","facet","chÅ‚opak","chlopak","pan"]
    female_kw = ["kobieta","dziewczyna","pani"]

    if any(k in t for k in male_kw): 
        return "M"
    if any(k in t for k in female_kw):
        return "K"

    # prosta heurystyka po imieniu: "jestem <imiÄ™>" lub "nazywam siÄ™ <imiÄ™>"
    m = re.search(r"(jestem|nazywam siÄ™|nazywam sie)\s+([A-ZÄ„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\-]+)", text, flags=re.I)
    if m:
        name = m.group(2)
        # wyjÄ…tki imion mÄ™skich na -a
        male_exceptions = {"Kuba","Barnaba","Kosma","Bonawentura","Ilya","Sasza","Nikita"}
        if name in male_exceptions or not name.endswith("a"):
            return "M"
        else:
            return "K"
    return None         

# === UI ===


text = st.text_area(
    label="", 
    label_visibility="collapsed",
    placeholder="Np.: â€Mam 34 lata, kobieta, 5 km w 27:30â€.",
    height=120,
    key="user_text",
)




if st.button("Policz", key="policz_main"):
    lf = get_langfuse()
    trace = lf_start_trace(lf, name="predykcja", input={"raw_text": text})


    try:
        data_raw = extract_with_llm(text)
        
        plec = data_raw.get("plec")
        if plec not in {"K","M"}:
            guessed = infer_gender_from_text(text)
            if guessed:
                data_raw["plec"] = guessed
        for k in REQUIRED:
            if not data_raw.get(k):
                raise ValueError(f"missing:{k}")
        data = Inputs(**data_raw)

        model, model_key = load_model()
        X = to_features(data)
        y_sec = float(model.predict(X)[0])

        # --- wynik dla uÅ¼ytkownika ---
        st.success(f"Szacowany wynik: {y_sec/60:.1f} min ({fmt_time(y_sec)})")
        st.caption(f"Model: {model_key}")

        # --- zapis do Langfuse ---
        if trace:
            trace.update(output={"pred": y_sec, "model_key": model_key})
            lf.flush()

    except Exception as e:
        st.error("Nie udaÅ‚o siÄ™ policzyÄ‡ wyniku, sprawdÅº czy wszystkie potrzebne dane zostaÅ‚y wprowadzone.")
        if trace:
            trace.update(tags=["error"], output={"error": str(e)})
            lf.flush()


